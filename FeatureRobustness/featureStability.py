"""
This script performs an analysis of the stability of feature selection on the
robust feature subsets.

INPUT: Configurations of the experiment are specified at the beginning of the 
script. Here, one can specify:
    Metric used to quantify selection stability.
    Path to the image perturbation experiment containing the robust feature 
    subsets (as generated by getRobustFeatures.py).
    Which robustness metrics to evaluate.
    How many samples to draw to estimate selection stability.
    How many features to test selection stability at.

OUTPUT: CSV file containing the selection stability for each metric and 
number of features selected. File will be  saved under the experiment folder 
pertaining to the specific image perturbation experiment.

Written by Abbas Shaikh, Summer 2023
"""

import os
import pandas as pd
import numpy as np
import scipy

from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from imblearn.combine import SMOTETomek
from imblearn.over_sampling import SMOTE

from sklearn.feature_selection import SelectKBest, RFE, SequentialFeatureSelector, mutual_info_classif, f_classif
from mrmr import mrmr_classif
from boruta import BorutaPy

### Configurations ###
stabilityMetric = lambda a, b: scipy.stats.pearsonr(a, b).statistic # Pearson
# stabilityMetric = lambda a, b: scipy.spatial.distance.jaccard(a, b) # Jaccard
# stabilityMetric = lambda a, b: 2 * sum (a * b == True) / (sum(a == True) + sum(b == True)) # Dice

perturbationPath = "D:\BAP1\Experiments\FeatureRobustness\RotationSizeAdaptation"
metrics = ["MFR-SDFR", "CMFR-CSDFR", "nRoA-Bias", "CCC", "ICC", "No Metrics"]
scaler = StandardScaler()
numResamples = 100
numFeatures = [1, 2, 5, 10, 20, 30, 40, 50]


### Loading Data and Labels ###
# Path to data directory and feature extraction experiment
dataPath = r"D:\BAP1\Data"
expirementPath = r"D:/BAP1/Experiments/FeatureExtraction/FullFeatureExtraction"

# Load extracted features and labels
features = pd.read_csv(os.path.join(expirementPath, "features.csv"))
labels = pd.read_csv(os.path.join(dataPath, "BAP1Labels.csv"))[["Case", "Somatic BAP1 Mutation Status"]]

# Convert labels (in Yes/No format) to binary format
labels.rename(columns = {"Somatic BAP1 Mutation Status":"BAP1"}, inplace = True)
labels["BAP1"] = labels["BAP1"].str.lower().replace(to_replace = ['yes', 'no'], value = [1, 0])

# Merge labels and features (will remove labels if we don't have features extracted)
features = pd.merge(features, labels, on = "Case", how = "left")

# Drop 'Case' column and features with null values
featuresNum = features.dropna(axis = 1).drop("Case", axis = 1)

# Create final features and labels dataframes
X, y = featuresNum.iloc[:,:-1], featuresNum.iloc[:,-1]

# Balance Dataset
smt = SMOTETomek(random_state = 100)
X, y = smt.fit_resample(X, y)


### Generate Samples of Dataset ###
X_resamples = []
y_resamples = []

for idx in range(numResamples):
    
    # Get sample and rescale feature values
    X_sample, y_sample = resample(X, y, random_state = idx)
    X_sample.loc[:] = scaler.fit_transform(X_sample)
    
    X_resamples.append(X_sample)
    y_resamples.append(y_sample)
 
    
### Get Feature Stability ###
featureRobustness = pd.read_csv(os.path.join(perturbationPath, "robustFeatures.csv"))

featureStability = {metric: [] for metric in metrics}
for metric in metrics:
    
    print("Testing Metric:", metric)
    robustFeatures = featureRobustness[metric].dropna()
    print(len(robustFeatures), "Total Features")
    
    # For each number of features selected
    for num in numFeatures:
        
        # For each sample of dataset
        selectedFeatureVectors = []
        for idx in range(numResamples):
            
            # Select feature subset
            X_robust = X_resamples[idx][X_resamples[idx].columns.intersection(robustFeatures)]
            
            # Select features
            featureSelector = SelectKBest(k = num, score_func = f_classif)
            featureSelector.fit(X_robust, y_resamples[idx])
            
            # Convert to binary feature selection vector
            featureVec = np.zeros(len(featureRobustness["No Metrics"]))
            featureVec[0:len(robustFeatures)] = featureSelector.get_support()
            selectedFeatureVectors.append(featureVec)
         
        # Get pairwise Pearson coefficients
        pairwiseStability = []
        for i in range(numResamples):
            for j in range(i + 1, numResamples):
                pairwiseStability.append(stabilityMetric(selectedFeatureVectors[i], selectedFeatureVectors[j]))
         
        # Get feature stabiliyt measure
        print("Mean Stability with", num, "Feature(s):", np.mean(pairwiseStability))
        featureStability[metric].append(np.mean(pairwiseStability))
    
    print()
    
### Save to CSV ###
stabilityDF = pd.DataFrame.from_dict(featureStability)
stabilityDF.insert(value = numFeatures, column  = "Number of Features", loc = 0)
stabilityDF.to_csv(os.path.join(perturbationPath, "featureStability.csv"), index = False)